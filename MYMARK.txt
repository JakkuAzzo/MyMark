






“MyMark”: 
A Decentralised Personalised Fingerprint and Detection Tool to Prevent Unauthorised Media Use 
(Project Proposal – Nathan Brown-Bennett – K2110813)
 
1. Introduction (Motivation, Background, Context & Research Problem)
Digital media can be effortlessly copied and shared, leading to rampant unauthorised use of images and videos online. Studies estimate that around 3 billion images are shared on the internet daily, and 85% are used without a proper license. This amounts to approximately 2.5 billion stolen images every day, causing enormous revenue loss and privacy violations for content creators . High-profile cases of photographers’ works being reused without permission and watermarks being removed are increasingly common – in fact, 68% of stolen images had their watermarks stripped by infringers. These trends underscore a pressing motivation for better tools to protect intellectual property in digital media.
Existing solutions for copyright protection have notable limitations. Traditional digital rights management and centralized content-monitoring systems (e.g. YouTube’s Content ID) are typically available only to large platforms and rely on central authorities. Content creators often resort to visible watermarks or manual web searches to spot misuse, which are ineffective against determined attackers (watermarks can be cropped or blurred) and impractical at internet scale. Digital watermarking and perceptual hashing techniques have been used to tag or identify media; however, many are proprietary or centralized, and adversaries continuously find ways around them. Moreover, the context of Network and Information Security calls for solutions that are not only technically robust but also distributed and tamper-resistant, reducing single points of failure or control.
Background & Context: 
Recent advances in decentralized networks and machine learning for media fingerprinting offer new opportunities to tackle this problem. Blockchain technology provides an immutable ledger to record ownership or embed fingerprints of content, ensuring evidence of original creation that cannot be easily altered. In parallel, perceptual hashing and deep learning allow detection of copies or derivatives of an image by comparing visual features rather than exact pixels. Contextually, this project sits at the intersection of digital forensics, copyright enforcement, and network security – it aims to empower individual users with a personalized tool to mark their media and detect misuse in a decentralised manner. By leveraging peer-to-peer or blockchain networks, the solution (“MyMark”) avoids reliance on any single service, aligning with the zero-trust ethos in information security (i.e., no central authority fully trusted) and promoting collective enforcement of usage rights.
Research Problem: 
How can we enable content creators to securely and imperceptibly mark their digital media with a unique fingerprint and detect unauthorised use of that media without relying on a centralized service? The problem can be stated as: Existing image protection methods either degrade the user experience or can be easily bypassed; there is a lack of a user-friendly, decentralised system for robustly fingerprinting personal media and detecting its illicit reuse. This project addresses that gap by designing “MyMark,” a system that combines imperceptible personalized watermarks (fingerprints) with a decentralised detection network. The aim is to embed a unique identifier into media content and to use a distributed monitoring approach to spot copies of that content on the internet, thereby preventing or at least promptly identifying unauthorised usage. The proposed research will explore this idea in depth, providing the necessary background, design, and evaluation to demonstrate its feasibility within the scope of an MSc project.
 
2. Aims and Objectives (Suitability & SMART obectives)
Project Aim: 
The primary aim of this MSc project is to develop and evaluate “MyMark,” a decentralized personalized fingerprinting and detection tool for digital media, to help prevent unauthorised use of images. This aligns with the Network and Information Security domain by focusing on securing digital assets (images/media) and detecting infringement in a distributed, tamper-resistant manner. The aim is suitable for an MSc level as it involves research, design, and implementation of a novel integration of existing technologies (digital watermarking, perceptual hashing, blockchain, and machine learning), with a strong emphasis on security considerations.
Objectives: 
To achieve this aim, the project is broken down into specific, measurable, achievable, relevant, and time-bound (SMART) objectives:
• Objective 1: Literature Review & Requirements – 
Research existing solutions in digital watermarking, perceptual image hashing, and blockchain-based copyright protection (by end of March 2025). This includes critically reviewing academic literature and case studies to identify strengths, limitations, and gaps. Measurable outcome: A literature review document and a clear set of system requirements/guidelines distilled from it.
• Objective 2: System Design – 
Design the MyMark system architecture (by April 2025) based on findings. This includes specifying how the personalized fingerprint will be embedded and extracted, how the decentralised ledger or network will store and verify fingerprints, and the overall workflow (from content registration to misuse detection). Measurable outcome: A design report and diagrams (system workflow, threat model) that satisfy the identified requirements. The design will be reviewed with the supervisor to ensure it is technically sound and achievable.
• Objective 3: Implementation of Fingerprinting Module – 
Develop a prototype module to embed and extract the personalized fingerprint in images (by May 2025). This will involve choosing an appropriate watermarking or hashing technique (such as a robust perceptual hash or invisible watermark) and coding it. The fingerprint should be imperceptible and minimally affect image quality, yet remain detectable after common transformations (resize, format change, etc.). Measurable outcome: A working code module that can take an image and output a “marked” image plus storeable fingerprint metadata. Success criteria include minimal visual distortion and the ability to recover the fingerprint from altered images.
 
• Objective 4: Implementation of Detection Module – 
Develop a detection algorithm/service that can identify the marked content across a set of images (or online) (by June 2025). This includes using perceptual hashing or feature matching (and possibly AI models like CLIP for semantic similarity) to find images that match or contain the fingerprint. If the project scope allows, this may involve a simple web crawler or using existing image search APIs in a decentralised fashion. Measurable outcome: A prototype that, given a query image or fingerprint, returns potential matches (with some similarity score or indication if the fingerprint is present). Performance (precision/recall of detection) will be measured on test cases.
• Objective 5: Blockchain/Database Integration – 
Integrate a secure decentralised ledger to store fingerprints and verify authenticity (by July 2025). The system will record the fingerprint (or a hash of it) and associated metadata (owner ID, timestamp) on a blockchain or distributed database. This ensures tamper-proof provenance—once an image’s fingerprint is registered, it serves as a permanent record of ownership. Measurable outcome: A basic private blockchain network (e.g., using Hyperledger Fabric or Ethereum testnet) or an alternative secure distributed store set up and interfaced with the application. Demonstration that the system can write a new entry when an image is registered and later read/validate entries during detection.
• Objective 6: Testing and Evaluation – 
Evaluate the complete MyMark system under various scenarios (by August 2025). This includes functional testing (does the system correctly embed and detect fingerprints) and security testing (resilience to common attacks like cropping, re-compression, slight alterations to images that might try to remove or obfuscate the fingerprint). It will also measure the efficiency of the detection (time to search or compare fingerprints) and the false positive/negative rates. Where possible, comparisons will be made with baseline methods (e.g., simple perceptual hash matching without the custom fingerprint, or a centralized reverse image search) to demonstrate improvements. Measurable outcome: An evaluation report with quantitative results (e.g., detection accuracy %, response times) and qualitative analysis of the system’s effectiveness and limitations.
• Objective 7: Documentation & Project Report – 
Document the research and development process and produce the final project dissertation (by early September 2025). This includes writing up the Introduction, Background, Methodology, Results, and Conclusion chapters, and preparing any supplementary materials (code, user guide). Measurable outcome: A comprehensive project report (~10,000 words) submitted to Kingston University, demonstrating critical analysis, technical detail, and reflections on ethical and security implications. This report will be completed and proofread by the submission deadline (mid-September 2025).

Each objective follows the SMART criteria: they are Specific (targeting a particular component or task), Measurable (with clear deliverables or criteria for completion), Achievable (feasible with the given time and resources of an MSc project), Relevant (directly contributing to the project aim and aligned with Network & Information Security focus), and Time-bound (each is assigned an expected completion timeframe as noted). Collectively, achieving these objectives will fulfill the project’s aim of creating and validating the MyMark tool for preventing unauthorised media use.

 
3. Initial Literature Review (Review of Relevant Work & References, Critical Analysis)
To ground the project in existing knowledge, this section reviews the state-of-the-art in media fingerprinting, digital watermarking, and decentralised copyright protection, identifying key solutions and gaps that MyMark will address. Emphasis is placed on academic, peer-reviewed sources in security, multimedia, and blockchain domains.
3.1 Digital Watermarking Techniques
Digital watermarking involves embedding information into a media file (image, video, audio) in a way that is ideally imperceptible to users but can be detected by the owner. The embedded information (the “watermark”) can be a logo, serial number, or cryptographic code that signifies ownership. Traditional watermarking algorithms modify the pixel values (for images) either in the spatial domain (directly altering pixel patterns) or in a transform domain (like frequency domain using DCT or wavelets). For example, a watermark might be inserted by slightly adjusting the brightness of certain image regions in a pattern, or by altering specific frequency coefficients of the image. The goal is to make the watermark robust against common edits—if someone crops, resizes, or compresses the image, the watermark should still be recoverable.
Watermarking has been extensively studied as a means of copyright protection. A key challenge is balancing robustness vs. imperceptibility: a strong watermark that survives many transformations might involve more significant changes to the image (risking perceptibility or quality loss), whereas a subtle watermark might be easily destroyed by simple edits. Another issue is that traditional watermarks alter the original content, which could be unacceptable for applications requiring exact original retention. An emerging solution is zero-watermarking, where the watermark information is derived from the content but not actually embedded into the image data – meaning the original image isn’t distorted at all. Instead, a “fingerprint” extracted from the image (like features or points) is combined with the watermark info and stored separately (e.g., in a database). This gives “perfect imperceptibility” since the media isn’t changed . However, classical zero-watermarking relies on a trusted third party to store the watermark or fingerprint, and it has difficulty proving ownership conclusively (since the evidence is external to the media).
 
Strengths and Weaknesses: 
Watermarking (including zero-watermarking) provides a proactive way to claim ownership – the owner can embed a unique code (like “Nathan’s Mark”) in all his images. If those images appear elsewhere, the code can be extracted to prove they are his. It’s a stronger proof than just a perceptual hash match, because a watermark can contain an explicit owner ID or secret that only the owner would have inserted. This addresses the scenario of disputed ownership: if two people have the same photo, the one with the embedded secret watermark can prove prior ownership. However, watermarks can often be removed or degraded by attackers: for example, adding a logo watermark on a photo can be removed by cropping or inpainting, and invisible watermarks can be destroyed by applying noise, blurring, or even printing and re-scanning an image. According to a report, over two-thirds of stolen images had their watermarks successfully removed by thieves, showing that conventional watermarking alone may not suffice. Additionally, watermarks embedded in the media could be detected and potentially forged by savvy adversaries – an attacker might try to copy the watermark from one image to another to confuse ownership claims.
Recent academic work has looked at making watermarks more secure and integrated with cryptography/blockchain. Xiao and He (2024) propose BB-RICP – a blockchain-based image copyright protection system using Hyperledger Fabric – which incorporates spread-spectrum watermarking to embed ownership info into images in a robust way. The watermark info (like an identifier) is also stored on a consortium blockchain to prevent tampering. This hybrid approach means even if someone tries to remove the watermark, the original record of it remains on the ledger. Another approach by Ren et al. (2021) uses blockchain with zero-watermarking: the watermark (copyright info) is not in the image itself but is computed from it and stored on the Ethereum blockchain. The extraction process involves pulling that info from the blockchain and verifying it against the suspect image via an XOR operation. Their experiments showed combining zero-watermarking with blockchain achieves lossless protection (no quality loss) and improved robustness compared to traditional methods. These works influence MyMark’s approach: by storing fingerprint data on a blockchain, we can mitigate the reliance on a third-party storage and make it harder for an adversary to falsify or erase ownership records. MyMark will likely adopt a lossless or imperceptible watermarking scheme, potentially similar to these, ensuring the user’s original image quality is preserved while still enabling later identification.
 
3.2 Perceptual Hashing and Content-Based Identification
Another major avenue of protection is through content-based identification, notably perceptual hashing. Perceptual hashing creates a compact fingerprint of an image based on its visual content, such that similar images yield similar hashes. This differs from cryptographic hashes (SHA-256, etc.), which change completely even if a single pixel is different (making them useless for identifying altered copies). Perceptual hash algorithms (like pHash, aHash, dHash) typically involve steps like: resize image to a standard size, convert to grayscale, apply a transform (DCT or wavelet) to capture dominant features, then quantize to a bit string. The result might be a 64-bit or 256-bit hash that changes only slightly for small image modifications. If someone reposts an image after resizing or adding a filter, the perceptual hash of that repost should still be close (with a small Hamming distance) to that of the original, enabling detection. This technique is widely used in industry: for example, PhotoDNA (developed by Microsoft and Hany Farid) is a perceptual hash that helps identify known illegal images (like child exploitation content) across the web by comparing hashes. Similarly, social media platforms use perceptual hashes to automatically flag uploads that match known copyrighted or harmful images.
Applications in Copyright Detection: 
Perceptual hashing is very relevant to MyMark’s detection tool. It allows scanning or comparing images without needing the original watermark. For instance, if a user’s image is published on a different site without permission, a web crawler could compute perceptual hashes of images found online and compare them to the hashes of the user’s originals recorded in a database. A match (within a tolerance) would indicate a likely copy, even if the image has been transformed (e.g., resized or slightly color-adjusted). Perceptual hash functions have been shown to be effective in finding copyrighted images even when a watermark was added or removed by someone else. They are a key part of digital forensics and have been used to detect deepfakes or fake news images by correlating them to known originals.
Limitations: 
While perceptual hashing is powerful, it is not foolproof. It may struggle with major transformations: e.g., if an image is heavily cropped to only a small part of the original, the hash could change significantly (missing many features). Conversely, two completely different images might coincidentally share some visual similarity that makes their hashes appear closer than expected (leading to false positives). Researchers have also demonstrated adversarial attacks on deep perceptual hashing algorithms – by applying subtle changes to an image specifically designed to confuse the hash, attackers can produce identical hashes for different images or very different hashes for the same image. This indicates that naive use of perceptual hashing in a security context can be vulnerable. To counter this, systems often combine perceptual hashing with other checks or use more robust hashing methods (like deep learning models that learn what features to hash).

Recent works have tried to enhance robustness. Deep perceptual hashing uses neural networks to learn embeddings or hashes that are resilient to more complex changes. Kim et al. (2021) introduced a photo copyright identification framework that detects infringements even after significant manipulations like collages or cropping. Their approach detects salient regions (ROIs) in images to focus on content that likely remained in a cropped copy, then generates binary descriptors (hashes) from those regions that are robust to geometric and color changes. They also add a verification step comparing the matching regions to reduce false positives. This two-stage approach (hashing + verification) significantly improved accuracy, reducing false positive rate by 2.8% compared to traditional methods. Such advancements suggest that combining multiple techniques yields better reliability.
For MyMark, perceptual hashing will serve as a first-line similarity check to spot potential matches for a user’s content. A likely strategy is to compute a perceptual hash for each registered image and store it (on the blockchain or in an index). When scanning for misuse, images with a hash within a certain distance to one of the registered hashes would be flagged. To make this more reliable, MyMark can incorporate additional features: for example, use robust feature descriptors (SIFT, ORB) to see if distinct patterns match between images, or use a neural network embedding (like the penultimate layer of a classification model) for a more discriminative fingerprint. Critical analysis: The benefit of perceptual hashing is that it doesn’t require modifying the image (passive detection) and can leverage large existing databases for search. The downside is the possibility of collisions (different images appearing similar) and evasion (clever modifications fooling the hash). MyMark will address these by (a) using a high-quality hashing algorithm (potentially even a learned one fine-tuned on the types of transformations expected), and (b) combining hashing with an embedded watermark for double verification. The watermark (if present) can serve as final proof, while the hash can cast a wide net to find candidates.

 
3.3 Face Recognition and Content-Based Signatures (FaceNet & CLIP)
Modern AI provides specialized models that effectively act as fingerprinting systems for specific content. FaceNet is a prime example in the domain of facial recognition – it learns to map face images into a 128-dimensional vector space such that the distance between two vectors indicates if they are the same person . With FaceNet, each face yields a unique “embedding”, and it achieved 99.63% accuracy on the LFW benchmark, essentially human-level performance . This shows the power of learned embeddings: even if a face photo is taken in different lighting or with minor edits, FaceNet will place them close in its feature space, correctly recognizing the person. For our project, FaceNet and similar techniques could be relevant if the media involves identifiable people or if the goal is to prevent unauthorised use of someone’s personal photos. A potential use-case is a photographer who wants to ensure their portrait shots of a client are not reused elsewhere; FaceNet could help recognize that client’s face in images found online, complementing other methods.
However, MyMark is not limited to faces – it must handle arbitrary imagery (landscapes, artwork, screenshots, etc.). For general image content, another model, OpenAI’s CLIP (Contrastive Language-Image Pretraining), is very promising. CLIP is a neural network trained on 400 million image-text pairs to create a joint embedding space for images and text. While its original purpose is to connect images with textual descriptions, CLIP’s image encoder on its own serves as a powerful image feature extractor. It produces a vector (e.g., 512-dimensional) for any image; images with similar content will end up with vectors that are closer together in that space. Researchers have begun using CLIP for tasks like detecting AI-generated images and finding duplicate content, by comparing these embeddings. The advantage of CLIP is its broad training – it can recognize high-level semantic similarity. For example, two different edits of the same photograph (one in color, one in grayscale, or one with a filter) will likely still be close in CLIP’s feature space because the core content is the same. This could help catch cases where perceptual hashes might fail due to pixel-level changes.
Existing research using CLIP or similar: 
An arXiv study by OpenAI researchers (2022) showed that a CLIP-based method could detect AI-generated images by noticing discrepancies in CLIP space compared to real images. While that is a different domain, it highlights that CLIP features are sensitive to subtle differences and could be harnessed for authenticity checks. Another work (Houston et al., 2023) introduced a system called DETECT that measures similarity of generated images to known copyrighted characters using a multimodal model (potentially akin to CLIP). They essentially check if an AI-generated image is too similar to a copyrighted one by using the model’s similarity score. This approach is directly relevant to MyMark’s goal of comparing images for copyright infringement: it suggests that we can use advanced models to flag when an image is “too close” to a protected original.
Role in MyMark: 
We plan to explore using CLIP (or a similar pre-trained model) in the detection module to complement perceptual hashing. The idea is to leverage CLIP’s semantic understanding: if someone heavily edits an image (changing colors, adding overlays), a simple hash might not catch it, but CLIP might still recognize the scene or objects as the same. For instance, if the original image has a red car on a street and a copycat converts it to a blue car, pHash might differ a lot due to color shift, but CLIP’s embedding will likely still encode “car on street” features similarly. Using CLIP embeddings, we could perform a nearest-neighbor search in the vector space (there are efficient libraries like FAISS for this purpose) to find candidates for unauthorized copies. This is computationally heavier than hashing but might be run periodically or on a smaller set of suspect images rather than across the entire internet. It’s an example of exploring alternatives: if simpler methods fail, a deep learning approach can be a fallback for tough cases. The main trade-off is computational cost and complexity – running CLIP on millions of images is non-trivial. Thus, a possible design is a tiered detection: first use perceptual hash to narrow down candidates (fast to compute and compare), then use a CLIP-based comparison on those candidates for confirmation.
Critical Analysis: 
FaceNet and CLIP demonstrate how learned embeddings outperform hand-crafted algorithms in capturing the essence of content. They significantly reduce false negatives (missing a match) by being invariant to many transformations. However, they also introduce new considerations: these models can be large and require GPU acceleration to run efficiently; incorporating them into a user-level tool might challenge performance and deployment. Additionally, neural networks can sometimes be “black boxes,” making it harder to explain why a false match happened. In a legal scenario, a straightforward watermark might be easier to present as evidence than a neural net similarity score. Therefore, MyMark will use these AI techniques to assist detection internally, but for evidentiary proof it will lean on more interpretable fingerprints (like an extracted watermark or an exact hash match). In summary, the literature suggests using a hybrid approach: a robust watermark or identifier for definitive ownership proof, combined with perceptual and AI-based matching for effective discovery of copies. This dual strategy leverages the strengths of each method while mitigating their individual weaknesses, and it forms the core idea that differentiates MyMark from single-tech solutions.

 
3.4 Decentralisation and Blockchain for Copyright Protection
Central to MyMark is the notion of decentralisation – removing the need for a trusted central authority in tracking and verifying media usage. Blockchain technology naturally comes into play here. Blockchain (distributed ledger) provides an append-only, tamper-evident record maintained by a network of nodes rather than a single database administrator. This is attractive for copyright matters because it can serve as an immutable timestamped registry of content ownership. Once a creator registers the fingerprint of their image on the blockchain, that entry is essentially permanent and verifiable by anyone. It’s like a notary service for digital content, but global and decentralized.
Recent studies and systems have applied blockchain to digital rights management:
• Content Provenance: 
Projects like Microsoft’s Ethereum-based DRM prototypes and startups in the art world have used blockchain to register digital art or photos as NFTs (non-fungible tokens). The NFT boom showed that people are interested in proving ownership of digital items. However, a limitation is that owning an NFT of an image doesn’t automatically prevent others from copying the image – it just proves you hold a record on blockchain. MyMark aims to go further by linking the blockchain record to an actionable detection mechanism.
• Blockchain DRM and Anti-Piracy: 
Academic proposals such as BB-RICP (mentioned earlier) use a permissioned blockchain (Hyperledger Fabric) to manage the lifecycle of image copyrights, from registration to tracking transfers or licenses. By using a consortium blockchain with Byzantine Fault Tolerance, they achieved good throughput and security without the high fees of public blockchains. They embed info into images and store evidence on-chain, thereby decentralizing the authentication process (no single server can secretly alter or delete rights data). Another study by Xie & Tang (2024) suggests a cross-chain blockchain system for copyright to address scalability issues of single chains – this is on the cutting edge, ensuring that the solution can grow without being limited by one network’s capacity.
• Zero-Watermarking + Blockchain: 
As discussed, Ren et al. (2021) solved the third-party trust issue of zero-watermarking by using blockchain to hold the watermark info. This way, the integrity of the watermark data is guaranteed (blockchain’s tamper resistance), and availability is improved (many nodes have it, so it won’t be lost).
 
Why Decentralisation for MyMark: 
The decentralised approach is not just a trendy choice; it directly addresses threats in the threat model. If MyMark relied on a centralized database to store fingerprints, an attacker who compromises that database could remove or alter records to cover their tracks or falsely claim someone’s image. With blockchain, any such tampering would be evident (due to consensus and cryptographic linking of blocks) and practically infeasible if the network is sufficiently distributed. It also prevents censorship or bias – no single company can decide to remove a user’s entries or shut down the service unilaterally. For content creators worldwide, a public or consortium blockchain could serve as a neutral ground to establish ownership claims and share fingerprint data without needing to trust each other. This is especially relevant when multiple parties need to verify the data (e.g., in court or in disputes, the blockchain record is an independent source).
Design Considerations: 
Using blockchain comes with choices: public vs private chain, consensus mechanism, data stored on-chain vs off-chain. Storing entire images on-chain is impractical (huge data and privacy issues), so MyMark will only store hashes or fingerprint metadata on-chain. Possibly, the system will store a cryptographic hash of the image or the secret watermark key on the ledger when the user registers it. This ensures that later, the user can prove an image was theirs by showing it produces the same hash, without the hash ever having been alterable. We might utilize a secure database or IPFS (InterPlanetary File System) for storing larger data (like a copy of the image or detailed features) with references on-chain. IPFS is a decentralized storage network, which could complement blockchain by hosting the images or fingerprints in a distributed way, referenced by content hash. Some research has combined blockchain with IPFS for copyright protection, noting that it pairs blockchain’s integrity with distributed storage’s efficiency.
Threats & Mitigations via Blockchain: 
A major threat in a fingerprinting system is someone else registering your content on the ledger before you do (a race condition / preemptive claim). Blockchain can actually make this transparent – the timestamp of registration is recorded, so the first person to register a given fingerprint is evident. If an adversary tries to register an image that isn’t theirs, they would need the actual image (for computing the fingerprint) – which they might have if they stole it, unfortunately. But MyMark can mitigate this by including in the fingerprint some secret only the legitimate owner knows. For example, the system could hash a combination of the image data and the owner’s secret key. That way, even if an attacker has the image, they cannot generate the same fingerprint without the key. This concept is akin to a digital signature on the content. The blockchain record might contain a public commitment, and the owner can prove knowledge of the secret if needed. These details will be fleshed out in the design, guided by literature on secure provenance.
Summary of  Initial Literature Review
In summary, the literature review reveals that no single existing solution fully solves unauthorised media use for individuals: watermarking alone is defeatable, perceptual hashing alone can miss clever modifications, and simple blockchain registries don’t actively detect misuse. MyMark’s novelty will be in synthesizing these approaches: embedding a hidden mark (for strong proof), using perceptual and AI methods to seek out copies, and leveraging blockchain for decentralized trust and integrity. By learning from prior art – e.g., using robust embedding techniques from Kim et al. to handle image manipulations, and using a blockchain ledger as in Ren et al. to remove third-party dependence – this project will build a cohesive tool that addresses key gaps identified:
• Gap 1: Lack of user-friendly, decentralised ownership registration – solved by an easy interface to register content on blockchain, abstracting technical complexity.
• Gap 2: Lack of effective automated detection for individuals – solved by integrating perceptual hashing and possibly CLIP-based search to continuously or periodically scan for matches, something currently done only by large providers.
• Gap 3: Trust and tamper-resistance – solved by blockchain; unlike a private database, the ledger ensures records can’t be quietly changed, and all actions (registrations, detections) are transparent and verifiable.
• Gap 4: Integration and personalization – MyMark will be personalized (each user’s content marked with their unique ID) and integrate the end-to-end process (from marking to monitoring to alerting), whereas existing tools often handle just one part (e.g., just scanning, or just watermark embedding) in isolation.
Thus, the research and prior solutions provide a solid foundation, and by critically analyzing them, we have shaped the vision for MyMark. The next sections detail how we will handle ethical aspects, what technologies will be used concretely, and how the research will be carried out to implement and test the proposed system.
 
4. Ethics: Relevance & Mitigation of Ethical Concerns
Any project dealing with content monitoring and user data must address ethical implications. Ethical considerations for MyMark fall into several areas: data privacy, consent, potential misuse, and research ethics compliance.
Data Privacy & Protection: 
MyMark will handle users’ personal media and produce digital fingerprints of that media. It is crucial that the system does not expose sensitive content or personal information inadvertently. Storing images or fingerprints on a public blockchain could raise privacy issues (since blockchain data is transparent and immutable). To mitigate this, MyMark’s design is to store only hashed or encrypted identifiers on-chain, not the images themselves. The actual images can remain with the user or in a secure database with controlled access. The fingerprint (e.g., a hash or watermark code) stored on the ledger will not reveal the image’s contents – it will be a random-looking string that only has meaning when the proper extraction key or original image is available. This approach follows privacy by design, ensuring that even if the blockchain is public, no personal data is directly on it. Additionally, any communication between the user’s device and the network (for registering or searching) will be encrypted to prevent eavesdropping on what content is being registered or queried.
Consent & Web Scanning: 
A detection tool might involve scanning websites or online platforms for matches. Ethically, web crawling should respect terms of service and robots.txt directives of websites. The project will use only publicly available data for testing the detection module (for example, a set of images from open datasets or one’s own published images on a test site). There is no intention to violate any platform’s policies or scrape personal data without permission. During development, testing will likely be on a closed set of images or using search APIs that are available, which should avoid ethical issues entirely. If future iterations were to scan the broader internet, careful consideration would be given to respecting intellectual property of others (the system targets finding copies of the user’s images, not spying on unrelated images).
False Positives & Accusations: 
An ethical concern in copyright detection is the risk of false accusations – mistakenly flagging someone’s content as unauthorized use when it’s not (e.g., they had a license or it’s a coincidence). To handle this, MyMark will treat detection results as leads for the user’s investigation rather than automatic takedown actions. The user (content owner) will always review any flagged case. The system will provide evidence (like the extracted watermark or similarity score) to support the decision. By keeping a human in the loop, we ensure no wrongful accusations are automated. Moreover, the fingerprint is unique to the owner’s copy, so if it’s found elsewhere, it’s a strong indicator of unauthorized use. In any ambiguous situation, the user can reach out through proper legal channels rather than the tool taking action on its own.
 
Bias & Fairness: 
The tool itself should apply equally to any user’s content and not discriminate. Since the fingerprinting and detection are based on technical features, there is little scope for human bias in the algorithm (unlike, say, face recognition which can have bias issues; our use of FaceNet, if any, will be limited to detection of the same person’s face and not for identifying who the person is, thus avoiding demographic bias issues). We will still be mindful that AI models like CLIP were trained on internet data that might contain biases; however, in the context of image similarity, this is not directly making judgments about people, so it is less of a concern. The results (alerts of a match) will be purely on content similarity metrics.
Ethics Approval & Compliance: 
As a student project, an ethics self-assessment will be completed at project start. We anticipate this project to be Low Risk: it does not involve experiments on people or sensitive personal data (only the student’s own or freely available images are used). It primarily involves software development. The Kingston University ethical guidelines will be followed. For instance, if any user study or feedback was to be taken (not planned as of now), we would seek consent and perhaps a formal ethics application. At this stage, since the project deals with the student’s implementation and testing, no additional human participants are involved. All datasets used will be either the student’s property or open-license images; hence, copyright of input data is respected. We also commit to properly cite any external code or dataset in the dissertation to maintain academic integrity.
Preventing Misuse of MyMark: 
Another ethical angle is ensuring MyMark itself is not misused. A bad actor should not be able to use it to, say, track someone else’s images without their permission or create false ownership claims. The project will consider including authentication for who can register content (initially, it will be a single-user prototype for the student). In a broader sense, if deployed, one might require users to prove ownership when registering (for example, upload the image file itself at registration to generate the fingerprint, which implies they possess it). This would deter users from registering random images they found (as they wouldn’t have the unaltered original in most cases). The blockchain’s transparency also means any claims are visible – it’s hard to secretly claim ownership without notice. In the project report, we will discuss these governance aspects though implementing them may be beyond the prototype’s scope.
Summary of Ethical Considerations
In conclusion, ethical considerations have been identified and will be continuously revisited. The project’s design choices (using hashing for privacy, user-in-the-loop for actions, focusing on personal content) inherently mitigate many concerns. By the time of implementation, an ethics checklist will be completed to confirm these measures. The supervisor will also review the plan to ensure compliance with all relevant ethical standards. By proactively addressing privacy, consent, and accuracy issues, we aim for MyMark to be not only effective but also responsible and trustworthy.
 
5. Technologies & Resources (Relevance of Tools, Alternatives Considered)
Implementing MyMark requires a blend of security, image processing, and distributed system technologies. This section outlines the chosen technologies and tools, explains why they are suitable, and notes alternatives considered and how they compare. Ensuring that each technology aligns with the project’s objectives (and is feasible to use within the timeframe) is a key consideration.
Image Perceptual Hashing Library: 
For generating and comparing image fingerprints, we will use or develop a perceptual hashing module. A likely choice is the open-source pHash library (or its Python equivalent) which implements algorithms like Average Hash, Difference Hash, and Discrete Cosine Transform (DCT) based pHash. These algorithms create a compact fingerprint that remains stable under minor image transformations, as described earlier. The use of pHash is justified by its proven track record in identifying near-duplicate images. Alternatively, we considered Microsoft PhotoDNA, which is very robust and used in industry; however, PhotoDNA is not open-source and would not be easily integrable into our project. Another alternative was to implement a custom perceptual hash (perhaps training a neural network for the task), but given the time constraints, leveraging an existing algorithm like DCT-based pHash is more pragmatic. It offers a good balance of simplicity and effectiveness for an initial prototype.
Invisible Watermarking Technique: 
To embed a personalized fingerprint into images, we will incorporate a digital watermarking method. We have two main paths: (a) a traditional embed-in-image approach, or (b) a zero-watermark approach. After reviewing literature, a promising choice is a frequency-domain watermark (e.g., slight modifications in the DCT or DWT coefficients of the image) because these tend to be more robust against compression and minor editing than spatial tweaks. We will likely embed a binary sequence that encodes the user ID or an image ID. One could use a spread-spectrum technique (as in BB-RICP) where the bits are hidden across many frequencies of the image, making it hard to remove without heavy image degradation. The reason for choosing an imperceptible watermark is to have an on-image identifier that can later be extracted to definitively confirm a match. As alternatives, we considered visible watermarks (like a semi-transparent logo). Visible marks are a strong deterrent but they mar the visual quality and can be removed fairly easily or avoided by cropping. Since our goal is not to deter by appearance but to trace misuse, invisible marks are preferable. We also considered forego embedding entirely and just rely on hashing (which avoids altering the image), but embedding provides that extra verification layer. A compromise is to do a zero-watermark: not altering the image, but computing a robust feature (like a salient points map) and combining it with the user’s info to store externally. If implementation of an embedder proves too complex or risky for image quality, we will adopt a zero-watermark approach where, for instance, a hash of the image plus user secret is stored on blockchain. This would still allow later proof of ownership (by showing you have the secret and image to produce that hash) but doesn’t allow the quick detection by scanning the image’s pixels for a code. On balance, we lean towards embedding a subtle watermark in the prototype to demonstrate the concept, and we will experiment to ensure it’s imperceptible.
 
Machine Learning Models (FaceNet, CLIP): 
As discussed, advanced ML models can bolster the detection capabilities. We plan to use OpenAI’s CLIP model (specifically the image encoder from a pretrained CLIP) to extract high-level features of images. The resource requirement for this is having access to a machine with a decent GPU, as CLIP’s neural network is large. We have the option of using a cloud service or a local machine with a GPU (for example, Google Colab or the University’s computing resources). For the prototype scale (a few thousand images at most), CLIP is usable. If not, an alternative is to use a smaller pre-trained CNN like ResNet-50 (pretrained on ImageNet) just to get feature vectors; this would be lighter while still providing semantic features for comparison. FaceNet might be integrated on a case-by-case basis if we specifically test on a dataset of face images. FaceNet’s model (available through open-source implementations) can be used to generate a 128-D fingerprint for faces and match them. We include FaceNet primarily to acknowledge an alternative approach to “fingerprinting” – it exemplifies how unique embeddings can be for specific content (faces), achieving near-perfect recognition . In practice, the MyMark prototype might not heavily use FaceNet unless a portion of evaluation involves face recognition (which could be an interesting extension: e.g., if someone’s portrait is used without permission, FaceNet could confirm the person in both images is the same, strengthening the case). The choice of models will be evaluated as we progress – if time permits, we’ll compare the detection improvements from using CLIP features versus just pHash to quantify the benefit of AI models.
Blockchain Platform: 
For the decentralized ledger component, our choice is a private/consortium blockchain deployment using Hyperledger Fabric or Ethereum (Ganache/local). Hyperledger Fabric is attractive because it’s designed for enterprise and allows setting up a network with nodes on a local machine, has no cryptocurrency requirements, and supports high transaction throughput with configurable consensus (we can use solo orderer or Raft just for a demo). It also has fine-grained control of who can access the network, which suits testing. The literature indicated Fabric was used successfully for image copyright systems due to its efficiency and PBFT consensus ensuring trust among known parties. Alternatively, a local Ethereum test network (using Ganache or Go-Ethereum in dev mode) could be used, writing smart contracts to handle registration of fingerprints. Ethereum brings the advantage of being closer to a public chain (should future deployment be on a public network), and tools for writing contracts (Solidity) are well-established. However, interacting with Ethereum involves more overhead (transactions, gas even if fake, etc.) and potential security pitfalls in smart contract coding. Given that the focus is not on creating complex tokenomics but simply on storing records, Fabric’s key-value ledger model might be simpler for prototype. We considered skipping blockchain and using a distributed database or just a regular database; but that would lose the decentralisation benefit. Another middle-ground is using a secure ledger database like Amazon QLDB which is centralized but tamper-evident; however, that is proprietary and not really decentralized (it just uses blockchain-like verifiability). So, we will implement with an actual blockchain framework to meet the spirit of the project.
Secure Database: 
In addition to the blockchain, we will have a standard database or data store for the application’s use. For example, user account information (if any), or mapping from an image ID to its fingerprint could be stored in a SQLite or PostgreSQL database for quick lookup. This database can be considered a cache or complement to the blockchain. If we use Fabric, it can store key-value pairs inherently (e.g., mapping imageID -> fingerprint); if using Ethereum, we can store minimal info on-chain and keep details in an off-chain database referenced by a hash pointer. The database will be secured (with authentication and encryption if needed) to ensure only the rightful user or the application can read sensitive info (like the secret keys or full image files).
Programming Languages & Frameworks: 
The implementation will likely be in Python for the hashing and AI parts, given the rich ecosystem (libraries like OpenCV for image processing, imagehash or PIL for quick hashing, PyTorch or TensorFlow for running CLIP/FaceNet). Python also has libraries for blockchain interaction (e.g., web3.py for Ethereum, or Fabric SDK for Python). If Fabric is used, parts of the chaincode might be written in Go or Node.js as required by Fabric, but we will stick to high-level frameworks to simplify. The choice of Python is due to its rapid prototyping capabilities and familiarity from coursework, and it is suitable for an MSc project of this nature. For the blockchain setup, if needed, we can use Docker containers (many Fabric samples are dockerized) – the resource includes YAML configurations that can bring up a local network of nodes. This will be documented but does add some complexity; an alternative if time is short is to simulate a blockchain with a simpler distributed log or even use an existing testnet (though interacting with a live testnet might be slow and introduce unpredictability). The plan is to use local infrastructure for deterministic behavior during testing.
Other Tools: 
We will utilize version control (Git) to manage code, and possibly Jupyter Notebooks for initial data experiments (like testing perceptual hash collision resistance on sample images). For the timeline and project management, a Gantt chart tool or project management software will be used (as evidenced by the work plan figure). If crawling or searching images on the web is attempted, tools like Selenium (for controlled browsing) or APIs like Google Custom Search (if allowable) could be used with caution to gather test data. However, the need for extensive crawling is limited in the scope; we may manually create scenarios of “unauthorized use” by making modified copies of images and seeing if the system catches them.
Resource Needs: 
Hardware – a personal computer with at least 8GB RAM; a GPU would significantly speed up CLIP and FaceNet processing (the university lab or cloud can be leveraged). Software – as mentioned: Python 3.x, libraries (OpenCV, NumPy, PyTorch), Docker for blockchain nodes, possibly the Hyperledger Fabric binary distribution. All these are free/open-source, aligning with budget constraints. Data – we will gather a small image dataset (maybe 50-100 images) for testing, including original images and various modified versions (cropped, filtered, etc.), some containing the watermark and some not, to test both false positive and false negative aspects.
Alternatives Considered Summary:
 We considered a range of alternatives at each layer (e.g., centralized vs decentralized DB, classical vs deep learning detection, visible vs invisible watermark). The chosen set is believed to offer the best balance of security and feasibility. For instance, using both watermark and perceptual hash is slightly redundant but in practice covers more bases (watermark for certainty, hash for search breadth). If performance issues arise, we might scale back (e.g., not use CLIP on every image, only on difficult cases) – this flexible design is possible because we’ve reviewed multiple methods. The use of blockchain is possibly overkill strictly for a prototype with one user, but it is essential to demonstrate the decentralisation concept and will be implemented in a lightweight manner.
Tech Stack Summary:
In conclusion, the technology stack for MyMark will consist of: (a) image processing tools for fingerprint embedding and extraction (perceptual hash, watermark algorithms), (b) machine learning models for enhanced detection (optional but likely CLIP features), (c) a blockchain ledger for secure, distributed storage of ownership data (Hyperledger Fabric or similar), and (d) supporting frameworks (Python, databases, etc.). This stack directly addresses the project requirements and each component’s relevance is backed by literature or industry practice. By combining these, MyMark aims to be a novel integration of known techniques – the innovation is in how they work together in a personalized, decentralised context.

 
5.2 Security Considerations: Threats and Mitigations
Throughout the selection of technologies, we have also kept in mind the threat model for the system itself and how each tech helps mitigate those threats:
• Threat: An attacker tries to register a fake ownership for someone else’s image (to later dispute the real owner).	Mitigation: The blockchain’s timestamp and the requirement of possessing the image/its fingerprint at registration help. Using a secret-based fingerprint (hash with a secret) means an attacker cannot generate the correct fingerprint without the secret, so they cannot successfully register a fake unless they also stole that secret. Technologies: cryptographic hashing and blockchain (immutability) mitigate this.
• Threat: An attacker copies an image and alters it slightly to evade detection (e.g., add noise or filter).	Mitigation: Use robust perceptual hashing and multi-feature comparison (with CLIP) to still catch the image. If they alter it enough to break perceptual hash, the watermark embedded (which is designed to survive typical noise addition within limits) might still be extractable. Thus by using both hashing and watermarking (and possibly deep features), the system makes evasion much harder. This justifies our multi-tech approach rather than relying on one method.
• Threat: Removal or obfuscation of watermark (e.g., cropping out a corner that contained the mark, or using software to detect and zero out the watermark).	Mitigation: Place the watermark in a distributed manner across the image (not just one corner), using spread-spectrum or multiple bits in various regions, so that removal would significantly degrade the image or be impractical. Also, if a watermark is truly removed, the perceptual hash of the image likely still matches the original (because removing a well-hidden watermark doesn’t drastically change appearance), so the hash-based detection can still flag it, albeit we lose the embedded proof. Redundancy between methods mitigates each other’s weaknesses.
• Threat: Blockchain network attacks (e.g., a 51% attack or node compromise on a small private blockchain).	Mitigation: Since this is a private or permissioned blockchain in prototype, we will secure the nodes (running locally or on trusted machines). In a broader deployment, using a consortium of known institutions (e.g., a coalition of photography societies) would make it very hard for any attacker to gain majority control. Fabric’s PBFT is robust against up to f malicious nodes out of 3f+1. For the project, demonstrating correct function with byzantine fault tolerance might be overkill, but we will note that security increases with number and independence of nodes.
• Threat: Unauthorized access to the system or misuse (like someone tries to use the detection tool to scan for images that aren’t theirs, possibly invading privacy).	Mitigation: This is more of an operational policy issue. The tool could enforce that you can only scan for content that you have registered (thus presumably your own). In the project, the user is the owner of all registered content, so it’s naturally enforced. In a real scenario, authentication and usage logs could help ensure the tool isn’t widely abused for surveillance beyond its intended use.
These threat mitigations rely on the chosen technologies (e.g., cryptography in hashing, robustness of watermark algorithm, design of the blockchain network), showing that our selection was also driven by security needs, not just functionality.

6. Research Methodology and Work Plan (Method, Evaluation Strategy & Timeline)
Research Methodology: 
This project will follow a design science research methodology, which is appropriate for developing and evaluating a novel artifact (the MyMark system) to solve a real-world problem. The stages of the methodology include:
a.	Problem Identification & Motivation: 
Already addressed in the proposal – clearly define the problem of unauthorized media use and motivate why MyMark is needed (based on literature and cases). (Deliverable: Problem statement in Introduction.)
b.	Define Objectives for the Solution: 
Based on the problem, specify what a successful solution must achieve. In our case, objectives were defined (e.g., must detect copies, be decentralised, etc.). (Deliverable: Aims and Objectives section, and requirements in design.)
c.	Design & Development: 
Design the architecture and components of MyMark and then implement the prototype. This involves creative synthesis of the technologies discussed. We will create architecture diagrams (system workflow showing how an image goes from user to blockchain to detection of misuse) and then write the code for each part (watermarking module, detection module, blockchain integration). We will document design decisions and ensure the system meets the objectives set. (Deliverable: Prototype system + design documentation.)
d.	Demonstration: 
Use the developed prototype to show how it solves the problem for some scenarios. We will set up test scenarios (e.g., a set of images marked with MyMark, and some “attacker” modifications of them) to demonstrate that unauthorized usage can be detected. Possibly, a small demo where an image is marked, then someone else tries to use it, and the system flags it and proves the watermark, will be recorded. (Deliverable: Demonstration examples, could be screenshots or a short video/gif, included in the report.)
e.	Evaluation: 
Rigorously evaluate how well MyMark meets the objectives. This includes functional tests (does it detect when it should, does the blockchain record remain consistent) and performance metrics. For evaluation, we will define metrics such as True Positive Rate (how many of the known misuse cases were caught), False Positive Rate (how often it flagged something that wasn’t actually the same content), and the resilience against specific transformation types (e.g., watermark survives up to X% noise or image resize). Security evaluation will be qualitative, analyzing each threat and how the system handles it (as we started doing in section 5). We will also evaluate the system’s efficiency: e.g., how long it takes to process an image or to search for matches in a database of a certain size. If available, comparison with an existing tool (perhaps comparing against TinEye or another reverse image search for detection capability) will be done to give context to the results. (Deliverable: Evaluation results and analysis in the dissertation.)
f.	Communication: 
Finally, the results and the artifact will be communicated through the final report (and any presentations necessary for the MSc module). This step is essentially the compilation of all findings into a coherent narrative, which will be the dissertation itself.
This methodology ensures the project is carried out systematically, with checkpoints that align to our objectives. We will use an iterative approach within this: for example, after initial design, we might implement a basic version of the detection module, test it, and then refine the design based on what was learned (iterating between design, development, and evaluation in small cycles). This is common in software-related research to gradually improve the artifact.

Work Plan & Timeline: 
The project work plan spans approximately 6-7 months (March 2025 to September 2025), which covers the remainder of the academic year. Key phases of the project and their timeline are illustrated in the Gantt chart below:

Figure 1: Proposed project timeline (March–July 2025) with key phases. Each bar indicates the duration of a task: Literature Review & Analysis (yellow); System Design & Architecture (orange); Implementing Fingerprinting Module (red); Implementing Detection Module (pink); Integrating Decentralized Ledger (blue); Testing & Evaluation (teal); and Report Writing & Submission (green). Milestones (vertical dotted lines) mark the transition between phases or key deliverables.

As shown in Figure 1, the project is divided into overlapping phases to maximize progress (some tasks continue while the next begins, ensuring efficient use of time). The major milestones and activities are as follows:
 
• March 2025 – Literature Review & Planning: 
Conduct an in-depth literature review (as partially summarized in this proposal) on digital watermarking, perceptual hashing, blockchain in DRM, and relevant case studies. Simultaneously, refine the project scope and requirements with the supervisor’s input. 
Milestone: Complete literature review document and initial requirement specification by end of March. Also, complete Ethics checklist/approval in this month before starting development work.
• April 2025 – System Design & Architecture: 
Design the MyMark system architecture this month. This includes deciding on the exact methods (choose specific watermark algorithm, hash algorithm, blockchain platform, etc.), and designing the system workflow diagram. Also, plan the interfaces between components (e.g., how the detection module queries the ledger, data structures for image fingerprints). 
Milestone: Finish a detailed design and present it to the supervisor for feedback by late April. Any necessary adjustments from feedback will be incorporated before implementation starts. By the end of April, set up the development environment and have preliminary code structure in place.
• May 2025 – Implement basic Fingerprinting Module: 
Focus on coding the module that takes an image and outputs a marked image plus fingerprint registration. This involves writing the watermark embedding function and testing it on sample images to ensure invisibility, as well as coding the extraction function to read the watermark from an image. In parallel, set up the chosen blockchain or database environment (e.g., initialize a Fabric network or an Ethereum node) and write a simple interface to add and retrieve records (this might spill into early June). Milestone: By end of May, the watermarking component should be working: we should be able to embed a mark and later detect it from a test image. Also, a basic blockchain transaction (e.g., writing a test entry and reading it) should be demonstrated by this time, even if not yet integrated fully with the image code.
• May 2025 – Implement Detection Module: 
Develop the module for detecting unauthorized use. This includes coding the perceptual hashing function (or using a library) and setting up a mechanism to compare a new image against stored fingerprints. If using CLIP or FaceNet, this is when to integrate those models: write code to generate CLIP embeddings and a function to compute similarity scores. Another part is developing a strategy for searching potential matches; this could be a simple linear search through all known fingerprints (acceptable if numbers are small) or using an index structure for speed. 
Milestone: By end of June, given an input image (which might be an image found “in the wild”), the system should output whether it thinks this image is one of the protected set, and if so, which one (and perhaps with what confidence). Essentially, the core detection functionality is completed this month. We should also have the blockchain integration refined – e.g., the detection module queries the ledger to get fingerprint data rather than a local list (if that’s in design).
• July 2025 – Integration & Security Hardening: Now the pieces come together. This phase will integrate the fingerprinting and detection modules into one cohesive application. For example, when a new image is registered, the system will both embed the mark and store the fingerprint on blockchain, and when scanning, it will use both perceptual matching and watermark checking. We will also address any security issues (ensuring the secret keys are handled properly, making sure the system is robust against bad inputs). During this phase, initial testing will begin to flush out bugs. We will try various scenarios manually. Additionally, if any optimization is needed (perhaps the detection is slow, so we improve it, or we adjust the watermark parameters to be more robust), we do it here. Milestone: End of July – MyMark prototype v1.0 is feature-complete. That means a user can go through the whole process: input an image, mark it, later run a check on a set of images and get a correct alert on any copy. A demonstration to the supervisor will be scheduled around this time to show progress and get feedback for final evaluation planning.
• August 2025 – Testing & Evaluation: This month is dedicated to systematically testing the system and gathering results for the dissertation. We will create a test suite: a collection of original images and multiple altered versions of each (simulating different unauthorized use cases: resized, cropped, recolored, format change, etc.). We will run the detection and record whether each case is detected or missed. Also, test for false alarms by presenting completely unrelated images to ensure they don’t accidentally match something. The resilience of the watermark will be tested by subjecting images to increasing levels of alteration until the watermark fails (if it does). Another aspect is performance testing – measure how quickly images can be processed, and how the blockchain query latency is (though on a local network it should be fast). If possible, this is also where a small user acceptance test could happen – for example, ask a colleague to use the tool with a couple of their own images to see if the workflow is understandable (this would be informal and within ethical bounds since it’s just tool testing, not personal data collection). Any issues found (bugs or needed improvements) will be fixed in this phase. We will iterate the evaluation: test -> refine -> test again, to improve the system until it meets the objectives reasonably well. Milestone: By mid/late August, have a compiled set of evaluation results (tables, graphs of performance) and finalize the system. Essentially, freeze the development by end of August to focus on writing.
• Early September 2025 – Documentation & Submission: With the project implementation complete and results in hand, the first two weeks of September will be devoted to writing the final project report (if not already started in parallel). The structure of the dissertation will likely mirror this proposal (with more detail): Introduction, Background (lit review), Methodology (design and implementation details), Results (evaluation findings), Discussion (analysis of objectives met, limitations, future work), Conclusion. We will ensure all sections are well-written and supported by the data gathered. Citations and references (in IEEE style) will be finalized. This period will also include proofreading and possibly reviewing with peers or the supervisor for feedback. Milestone: Submit the dissertation by the official deadline (around mid-September 2025 as per the MSc timeline).

Throughout the project, we will have fortnightly meetings with the supervisor (Eckhard Pfluegel) to report progress and get guidance, which ensures the project stays on track and any issues are promptly addressed. We will also maintain a project diary/log to reflect on what was done, which helps in writing the methodology chapter later.

Post-Submission (if applicable): Although not part of this timeline, it’s worth noting that after submission, there might be a viva or presentation. Preparing for that (with slides or demo ready) would happen after the dissertation is submitted, using the remaining time before the final assessment.

Conclusion of Work Plan: By following this work plan, the project breaks down a large task into manageable segments with clear outputs at each stage. This staged approach mitigates risk – for instance, if certain advanced features (like CLIP integration) prove too time-consuming, we will know by June and can adjust scope (the basic detection with pHash will still be there to ensure the project’s success). The timeline also reserves a good amount of time for testing and writing, which are often underestimated tasks. The inclusion of a Gantt chart (Figure 1) provides a visual guide to stay organized and measure progress against time.

Finally, by delivering on each interim milestone, we aim to meet the marking criteria across all sections: demonstrating a solid introduction and background (from the literature review work), achieving the technical objectives (through the iterative development and integration), considering ethics (reviewed prior to implementation), using appropriate technologies (as planned and justified), and conducting a thorough evaluation (with results in August feeding into the final report). The outcome will be a well-rounded MSc project that not only builds a working prototype but also contributes insights into the efficacy of decentralised, AI-assisted approaches for copyright protection in the digital age.

